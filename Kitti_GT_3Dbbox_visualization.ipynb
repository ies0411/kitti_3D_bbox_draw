{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9529b633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "[Open3D INFO] Resetting default logger to print to terminal.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from copy import deepcopy\n",
    "from os import path as osp\n",
    "import open3d as o3d\n",
    "from open3d.web_visualizer import draw\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "lidar_path ='/home/server-003/workspace/data/superb_mobis/jupyter_apps/asset/005be846-3ada-4f4c-985e-5fbc0b136b2f/pointclouds_00000001.bin'\n",
    "calib_path ='/home/server-003/dl/mmdetection3d/data/superb/training/calib/000000.txt'\n",
    "label_path ='/home/server-003/dl/mmdetection3d/data/superb/training/label_2/000000.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4aedf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def depth_color(val, min_d=0, max_d=120):\n",
    "    \"\"\" \n",
    "    print Color(HSV's H value) corresponding to distance(m) \n",
    "    close distance = red , far distance = blue\n",
    "    \"\"\"\n",
    "    np.clip(val, 0, max_d, out=val)  # max distance is 120m but usually not usual\n",
    "    return (((val - min_d) / (max_d - min_d)) * 120).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a497a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bin(bin_path):\n",
    "    points = np.fromfile(bin_path, dtype=np.float32).reshape(-1, 4)\n",
    "    return points[:, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3126d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_calib_param(filepath):\n",
    "    \"\"\" \n",
    "    get Rotation(R : 3x3), Translation(T : 3x1) matrix info \n",
    "    using R,T matrix, we can convert velodyne coordinates to camera coordinates\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        file = f.readlines()\n",
    "\n",
    "        for line in file:\n",
    "            (key, val) = line.split(':', 1)\n",
    "            if key == 'Tr_velo_to_cam':\n",
    "                RT = np.fromstring(val, sep=' ')\n",
    "                RT = RT.reshape(3, 4)\n",
    "        \n",
    "    return RT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cb51ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_param(filepath):\n",
    "    \"\"\" \n",
    "    get Rotation(R : 3x3), Translation(T : 3x1) matrix info \n",
    "    using R,T matrix, we can convert velodyne coordinates to camera coordinates\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        file = f.readlines()\n",
    "        values=[]\n",
    "        label_id=[]\n",
    "        for line in file:\n",
    "            strings = line.split(' ')\n",
    "            value= np.asarray(np.array(strings[1:]), np.float32).reshape(1,-1)\n",
    "            label_id.append(strings[0])\n",
    "            values.append(value)\n",
    "            \n",
    "    return np.array(label_id),np.array(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "728324bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_id,values=get_label_param(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afd56124",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "velo_points = load_bin(lidar_path)\n",
    "x = velo_points[:, 0]\n",
    "y = velo_points[:, 1]\n",
    "z = velo_points[:, 2]\n",
    "dist = np.sqrt(x**2+y**2+z**2)\n",
    "ones = np.ones([velo_points.shape[0],2]).transpose()\n",
    "ones = ones*255\n",
    "color=depth_color(dist,0,70)\n",
    "color=np.ceil(np.array([color]))\n",
    "colors = np.concatenate((color,ones),axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c801b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "extrinsic_param = get_calib_param(calib_path)\n",
    "homo=np.array([0,0,0,1]).reshape(1,4)\n",
    "extrinsic_param_homo = np.concatenate([extrinsic_param,homo],axis=0)\n",
    "cam_to_lidar = np.linalg.inv(extrinsic_param_homo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8a2be02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] Window window_0 created.\n",
      "[Open3D INFO] EGL headless mode enabled.\n",
      "[Open3D INFO] ICE servers: {\"stun:stun.l.google.com:19302\", \"turn:user:password@34.69.27.100:3478\", \"turn:user:password@34.69.27.100:3478?transport=tcp\"}\n",
      "FEngine (64 bits) created at 0x7fc988008b20 (threading is enabled)\n",
      "[Open3D INFO] Set WEBRTC_STUN_SERVER environment variable add a customized WebRTC STUN server.\n",
      "[Open3D INFO] WebRTC Jupyter handshake mode enabled.\n",
      "EGL(1.5)\n",
      "OpenGL(4.6)\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n",
      "\u001b[1;33m[Open3D WARNING] invalid color in PaintUniformColor, clipping to [0, 1]\u001b[0;m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/intel/isl/isl.c:2105: FINISHME: ../src/intel/isl/isl.c:isl_surf_supports_ccs: CCS for 3D textures is disabled, but a workaround is available.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e00bed7551941cf98bbc5fa7f2c4146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "WebVisualizer(window_uid='window_0')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceServers\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/call\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/addIceCandidate\n",
      "[Open3D INFO] [Called HTTP API (custom handshake)] /api/getIceCandidate\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ServerDataChannel, state: open, peerid: 0.6289977270313087\n",
      "[Open3D INFO] DataChannelObserver::OnStateChange label: ClientDataChannel, state: open, peerid: 0.6289977270313087\n",
      "[Open3D INFO] Sending init frames to window_0.\n"
     ]
    }
   ],
   "source": [
    "center = values[:,:,10:13].squeeze()\n",
    "one=np.ones(center.shape[0]).reshape(4,1)\n",
    "center_cam_homo = np.concatenate([center,one],axis=1)\n",
    "\n",
    "size = values[:,:,7:10].squeeze()\n",
    "rot = values[:,:,13].squeeze().reshape(-1,1)\n",
    "\n",
    "center_lidar = np.matmul(cam_to_lidar,center_cam_homo.transpose())\n",
    "center_lidar = center_lidar.transpose()\n",
    "center_lidar = center_lidar[:,:3]\n",
    "\n",
    "dim=np.empty(size.shape)\n",
    "\n",
    "dim[:,0]=size[:,1]\n",
    "dim[:,1]=size[:,2]\n",
    "dim[:,2]=size[:,0]\n",
    "\n",
    "center_lidar[:,2] =  center_lidar[:,2] +(size[:,2] / 2)\n",
    "\n",
    "\n",
    "\n",
    "yaw = np.zeros([center.shape[0],3])\n",
    "yaw[:,2]=rot[:,0]\n",
    "\n",
    "\n",
    "draw_box = []\n",
    "cloud = o3d.geometry.PointCloud()\n",
    "cloud.points = o3d.utility.Vector3dVector(velo_points[:,:3])\n",
    "cloud.colors = o3d.utility.Vector3dVector(colors.transpose())\n",
    "draw_box.append(cloud)\n",
    "\n",
    "for i in range(center.shape[0]):\n",
    "    rot_mat = o3d.geometry.get_rotation_matrix_from_xyz(yaw[i])\n",
    "    box3d = o3d.geometry.OrientedBoundingBox(center[i], rot_mat, dim[i])\n",
    "    draw_box.append(box3d)\n",
    "\n",
    "\n",
    "draw(draw_box)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
